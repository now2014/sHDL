[{"path":[]},{"path":[]},{"path":"https://now2014.github.io/sHDL/articles/Example.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Example of sHDL","text":"install latest version sHDL package via Github, run following commands R: data.table package also required example:","code":"# install required packages install.packages(c(\"RhpcBLASctl\", \"dplyr\", \"parallel\")) remotes::install_github(\"now2024/sHDL\") install.packages('data.table')"},{"path":[]},{"path":"https://now2014.github.io/sHDL/articles/Example.html","id":"pre-computed-ld-reference-panels","dir":"Articles","previous_headings":"Data preparation","what":"Pre-computed LD reference panels","title":"Example of sHDL","text":"three publically available pre-computed autosome LD reference panels European-ancestry population (335,265 Genomic British individuals UK Biobank) HDL: Panel 1. QCed UK Biobank Axiom Array (307,519 SNPs): Panel 2. QCed UK Biobank imputed HapMap2 (769,306 SNPs): Panel 3. QCed UK Biobank imputed HapMap3 (1,029,876 SNPs): may download one reference panel according SNP density GWAS summary statistics, build LD reference panel. Alternatively, can download reference panels via Baidu Netdisk referring FAQ. , illustrate usage sHDL Panel 2. QCed UK Biobank Axiom Array. Step 01. Download LD reference panel. Step 02. Extract files archive.","code":"wget -c -t 1 \\   https://www.dropbox.com/s/fuvpwsf6r8tjd6c/UKB_array_SVD_eigen90_extraction.tar.gz?dl=0 \\   --no-check-certificate -O /path/to/UKB_array_SVD_eigen90_extraction.tar.gz wget -c -t 1 \\   https://www.dropbox.com/s/4vuktycxz1an6sp/UKB_imputed_hapmap2_SVD_eigen99_extraction.tar.gz?dl=0 \\   --no-check-certificate -O /path/to/UKB_imputed_hapmap2_SVD_eigen99_extraction.tar.gz wget -c -t 1 \\   https://www.dropbox.com/s/6js1dzy4tkc3gac/UKB_imputed_SVD_eigen99_extraction.tar.gz?dl=0 \\   --no-check-certificate -O /path/to/UKB_imputed_SVD_eigen99_extraction.tar.gz wget -c -t 1 https://www.dropbox.com/s/fuvpwsf6r8tjd6c/UKB_array_SVD_eigen90_extraction.tar.gz?dl=0 \\ --no-check-certificate -O /your/path/to/UKB_array_SVD_eigen90_extraction.tar.gz # checking the md5 = ff3fadd7ea08bd29759b6c652618cd1f md5sum /your/path/to/UKB_array_SVD_eigen90_extraction.tar.gz  # extraction tar -xvf /your/path/to/UKB_array_SVD_eigen90_extraction.tar.gz"},{"path":"https://now2014.github.io/sHDL/articles/Example.html","id":"gwas-summary-statistics","dir":"Articles","previous_headings":"Data preparation","what":"GWAS summary statistics","title":"Example of sHDL","text":"can test dataset HDL directly: can prepare data following: Step 01. Download Height GWAS summary statistics GIANT consortium. Step 02. Load GWAS summary statistics R. Step 03. Select & rename required 4 columns sHDL: SNP: rsid variants A1: effect allele A2: allele Z: GWAS Z-score N: Sample size Notice: sHDL automatically aligns A1 allele input GWAS summary statistics LD reference panel, data wrangling can skipped.","code":"data(gwas1.example, package='HDL') # GWAS summary statistics from the Neale Lab round 2 GWAS of UK Biobank of birth weight. gwas.df <- gwas1.example[, c('SNP', 'A1', 'A2', 'Z', 'N')] saveRDS(gwas1.example, file='gwas.df.rds') # save the gwas.df for sHDL wget -c https://portals.broadinstitute.org/collaboration/giant/images/f/f7/GIANT_HEIGHT_YENGO_2022_GWAS_SUMMARY_STATS_EUR.gz gwas.df <- data.table::fread('/path/to/GIANT_HEIGHT_YENGO_2022_GWAS_SUMMARY_STATS_EUR.gz', fill=TRUE, header=TRUE)  head(gwas.df, 5) # show the first five rows #           SNPID       RSID CHR    POS EFFECT_ALLELE OTHER_ALLELE EFFECT_ALLELE_FREQ         BETA      SE        P       N # 1: 1:566875:C:T  rs2185539   1 566875             T            C           0.002800 -0.046315600 0.03930 0.238128  537968 # 2: 1:728951:C:T rs11240767   1 728951             T            C           0.000356  0.167358000 0.12600 0.185025   85591 # 3: 1:734462:A:G rs12564807   1 734462             A            G           0.893000  0.004656900 0.01100 0.672866  112953 # 4: 1:752721:A:G  rs3131972   1 752721             G            A           0.840000  0.000544089 0.00284  0.84811  615932 # 5: 1:754182:A:G  rs3131969   1 754182             G            A           0.865000  0.001333110 0.00185 0.470389 1100634 gwas.df$Z <- gwas.df$BETA / gwas.df$SE # calculate the GWAS Z-score gwas.df <- gwas.df[, c('RSID', 'EFFECT_ALLELE', 'OTHER_ALLELE', 'Z', 'N')] colnames(gwas.df) <- c('SNP', 'A1', 'A2', 'Z', 'N')  head(gwas.df, 5) #           SNP A1 A2          Z       N # 1:  rs2185539  T  C -1.1785140  537968 # 2: rs11240767  T  C  1.3282381   85591 # 3: rs12564807  A  G  0.4233545  112953 # 4:  rs3131972  G  A  0.1915806  615932 # 5:  rs3131969  G  A  0.7206000 1100634  saveRDS(gwas.df, file='gwas.df.rds') # save the gwas.df for sHDL"},{"path":"https://now2014.github.io/sHDL/articles/Example.html","id":"genomic-annotation","dir":"Articles","previous_headings":"Data preparation","what":"Genomic annotation","title":"Example of sHDL","text":"example, create binary annotation genes based gene locations (hg19). Step 01. Download gene locations information GeneBreak package. Step 02. Create binary annotation genes. Notice: sHDL automatically align D LD reference panel according rsid, set weights missing variants LD reference panel ZERO.","code":"wget -c https://code.bioconductor.org/browse/GeneBreak/blob/RELEASE_3_18/data/ens.gene.ann.hg19.rda load('ens.gene.ann.hg19.rda') # load ens.gene.ann.hg19 LD.path <- '/your/path/to/UKB_array_SVD_eigen90_extraction'  ## extract gene locations ## gene.pos <- unique(ens.gene.ann.hg19[, c(3:5)]) colnames(gene.pos) <- c('chrom', 'start', 'end') autosomes <- as.character(1:22) gene.pos <- gene.pos[gene.pos$chrom %in% autosomes, ] gene.pos$chrom <- as.numeric(gene.pos$chrom)  ## extract variants position from LD reference panel ## bim <- do.call(rbind, lapply(   sHDL:::list.LD.ref.files(LD.path, suffix='.bim'), data.table::fread, header=FALSE )) bim <- bim[, c(2, 1, 4)] colnames(bim) <- c('SNP', 'chrom', 'pos')   ## match annotated variants ## gene2snp <- function(i, j){   cur.chrom <- gene.pos[j, 'chrom']   s <- gene.pos[j, 'start']   e <- gene.pos[j, 'end']   bim <- bim[bim$chrom == cur.chrom, ]   bim <- bim[bim$pos >= s & bim$pos <= e, ]   snps <- unique(c(i, bim$SNP))   nsnps <- length(snps)   if(j %% 1000 == 0) cat(sprintf(     '# of processed genes %d: # of annotated %d variants (%.2f%%) \\n',     j, nsnps, nsnps/M*100   ))   return(snps) } M <- nrow(bim) snps <- Reduce(gene2snp, 1:nrow(gene.pos), init=c())  ## create the annotation weights for sHDL ## D <- rep(1, length(snps)) names(D) <- snps  saveRDS(gwas.df, file='D.rds') # save the annotation weights for sHDL"},{"path":"https://now2014.github.io/sHDL/articles/Example.html","id":"run-shdl","dir":"Articles","previous_headings":"","what":"Run sHDL","title":"Example of sHDL","text":"sHDL finish ~3 mins 4 CPU cores. message console analysis (birth weight HDL) :","code":"library(sHDL)  LD.path <- '/your/path/to/UKB_array_SVD_eigen90_extraction' gwas.df <- readRDS('gwas.df.rds') D <- readRDS('D.rds')  t0 <- Sys.time() res <- sHDL::sHDL(D, gwas.df, LD.path, nthreads=4, stepwise=TRUE, lam.cut=1, mode='memory', Dr.path=NULL) print(Sys.time() - t0) Formating GWAS summary statistics ...  307519 out of 307519 (100%) SNPs in reference panel are available in the GWAS.   Converting z (D) to zr (Dr) ...  Applied `minmax` weight nomalization on 147849 (48.078%) annotated variants. The theoretical upper boundary for enrichment fold is 2.080. Optimizing ...  Optimization done in 63.731 seconds.  time    63.7308533191681 fold    1.27398058787877 h2      0.16391651163241 intercept       0.963235890727237 fold.se 0.0259721362117597 h2.se   0.00545604327753226 intercept.se    0.0106589577723641 fold.p  5.13295973147164e-26 h2.p    2.68604947190569e-198 intercept.p     0 stepwise        TRUE converged       TRUE optim.message   CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL Time difference of 2.521161 mins"},{"path":[]},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"missing-snps-warning","dir":"Articles","previous_headings":"","what":"Missing SNPs warning","title":"Mismatched LD reference panel","text":"matched LD reference panel vital analysis GWAS summary statistics. running sHDL (HDL), may encounter following warning message: default, sHDL (HDL) fills GWAS z-scores zeros SNPs LD reference panel missing.","code":"Warning: More than 1% SNPs in reference panel are missed ... This may generate bias in estimation. Please make sure that you are using correct reference panel."},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"solution","dir":"Articles","previous_headings":"","what":"Solution","title":"Mismatched LD reference panel","text":"address issue, provide function rebuild LD reference panel removing missed SNPs. Warning: GWAS summary statistics severe missingness, heritability may severely underestimated efficiency might lost. rebuilding process resolve mismatch cross-ancestry LD structures.","code":""},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Mismatched LD reference panel","text":"Suppose gone tutorial prepared LD reference panel, installed sHDL HDL package. example, demo QCed UK Biobank Axiom Array (307,519 SNPs) reference panel.","code":""},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"simulate-mismatched-gwas-snps","dir":"Articles","previous_headings":"Example","what":"Simulate mismatched GWAS SNPs","title":"Mismatched LD reference panel","text":"simulate mismatched GWAS SNPs, randomly subset 80% SNPs LD reference panel.","code":"library(sHDL) LD.path <- '/your/path/to/UKB_array_SVD_eigen90_extraction' all.snps <- do.call(rbind, lapply(sHDL:::list.LD.ref.files(LD.path, suffix='.bim'), read.table, header=FALSE))[, 2] set.seed(1234) gwas.snps <- sample(all.snps, size=floor(length(all.snps) * 0.8), replace=FALSE)"},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"re-build-the-ld-reference-panel","dir":"Articles","previous_headings":"Example","what":"Re-build the LD reference panel","title":"Mismatched LD reference panel","text":"rebuild LD reference panel gwas.snps store new LD reference panel /path//new/UKB_array_SVD_eigen90_extraction. process may take , can put following code script run background nohup. message console process:","code":"LD.path.new <- '/path/to/new/UKB_array_SVD_eigen90_extraction' sHDL.reduct.dim(LD.path, gwas.snps, LD.path.new, nthreads = 8) # run with 8 CPU cores Cleaning the new directory... Updating chr1_1 in 21.80 seconds: 6477 (out of 8090) SNPs are kept. Updating chr1_2 in 21.22 seconds: 6468 (out of 8090) SNPs are kept. Updating chr1_3 in 21.69 seconds: 6493 (out of 8090) SNPs are kept. Updating chr2_1 in 21.14 seconds: 6502 (out of 8156) SNPs are kept. Updating chr2_2 in 21.81 seconds: 6558 (out of 8156) SNPs are kept. Updating chr2_3 in 22.30 seconds: 6487 (out of 8154) SNPs are kept. Updating chr3_1 in 15.25 seconds: 5573 (out of 6935) SNPs are kept. Updating chr3_2 in 14.38 seconds: 5502 (out of 6935) SNPs are kept. Updating chr3_3 in 14.37 seconds: 5524 (out of 6935) SNPs are kept. Updating chr4_1 in 37.38 seconds: 7905 (out of 9777) SNPs are kept. Updating chr4_2 in 37.14 seconds: 7870 (out of 9776) SNPs are kept. Updating chr5_1 in 31.47 seconds: 7363 (out of 9260) SNPs are kept. Updating chr5_2 in 31.76 seconds: 7396 (out of 9260) SNPs are kept. Updating chr6_1 in 3.75 seconds: 3054 (out of 3825) SNPs are kept. Updating chr6_2 in 13.50 seconds: 5386 (out of 6757) SNPs are kept. Updating chr6_3 in 14.17 seconds: 5431 (out of 6756) SNPs are kept. Updating chr7_1 in 25.18 seconds: 6931 (out of 8576) SNPs are kept. Updating chr7_2 in 27.01 seconds: 6880 (out of 8575) SNPs are kept. Updating chr8_1 in 20.67 seconds: 6347 (out of 7954) SNPs are kept. Updating chr8_2 in 21.24 seconds: 6389 (out of 7953) SNPs are kept. Updating chr9_1 in 15.26 seconds: 5575 (out of 6949) SNPs are kept. Updating chr9_2 in 14.73 seconds: 5579 (out of 6948) SNPs are kept. Updating chr10_1 in 19.80 seconds: 6200 (out of 7742) SNPs are kept. Updating chr10_2 in 20.10 seconds: 6138 (out of 7741) SNPs are kept. Updating chr11_1 in 17.51 seconds: 5962 (out of 7513) SNPs are kept. Updating chr11_2 in 17.70 seconds: 6038 (out of 7513) SNPs are kept. Updating chr12_1 in 17.84 seconds: 5964 (out of 7470) SNPs are kept. Updating chr12_2 in 17.99 seconds: 5983 (out of 7469) SNPs are kept. Updating chr13_1 in 8.01 seconds: 4386 (out of 5495) SNPs are kept. Updating chr13_2 in 8.21 seconds: 4433 (out of 5495) SNPs are kept. Updating chr14_1 in 7.03 seconds: 4076 (out of 5094) SNPs are kept. Updating chr14_2 in 6.39 seconds: 3979 (out of 5094) SNPs are kept. Updating chr15_1 in 6.50 seconds: 4026 (out of 5023) SNPs are kept. Updating chr15_2 in 6.45 seconds: 4021 (out of 5023) SNPs are kept. Updating chr16_1 in 8.47 seconds: 4494 (out of 5592) SNPs are kept. Updating chr16_2 in 8.46 seconds: 4472 (out of 5591) SNPs are kept. Updating chr17_1 in 6.92 seconds: 4123 (out of 5172) SNPs are kept. Updating chr17_2 in 6.98 seconds: 4115 (out of 5171) SNPs are kept. Updating chr18_1 in 38.63 seconds: 7818 (out of 9783) SNPs are kept. Updating chr19_1 in 26.94 seconds: 6991 (out of 8711) SNPs are kept. Updating chr20_1 in 25.60 seconds: 6797 (out of 8512) SNPs are kept. Updating chr21_1 in 6.81 seconds: 3957 (out of 4988) SNPs are kept. Updating chr22_1 in 8.26 seconds: 4352 (out of 5420) SNPs are kept. [1] \"/path/to/new/UKB_array_SVD_eigen90_extraction\""},{"path":"https://now2014.github.io/sHDL/articles/Rebuild.html","id":"test-the-new-ld-reference-panel","dir":"Articles","previous_headings":"Example","what":"Test the new LD reference panel","title":"Mismatched LD reference panel","text":"Test sHDL::sHDL Test HDL::HDL.h2","code":"data(gwas1.example, package='HDL') M <- nrow(gwas1.example) set.seed(1234) D <- rbinom(M, 1, 0.1) # random D vector names(D) <- gwas1.example$SNP  res.sHDL <- sHDL::sHDL(   D, gwas1.example, LD.path.new, nthreads=4,   stepwise=TRUE, lam.cut=1, Dr.path=NULL, mode=\"memory\" ) # Formating GWAS summary statistics ...  # 246015 out of 246015 (100%) SNPs in reference panel are available in the GWAS. # Converting z (D) to zr (Dr) ...  # Applied `minmax` weight nomalization on 24634 (10.013)% annotated variants. # The upper boundary for enrichment fold is 9.987. # Optimizing ...  # Optimization done in 27.523 seconds.  # time  27.5229136943817 # fold  1 # h2  0.150313183380116 # intercept 0.985128189915527 # fold.se 0.126907671398178 # h2.se 0.00564781178384186 # intercept.se  0.012627945250898 # fold.p  1 # h2.p  4.62367704900812e-156 # intercept.p 0 # stepwise  TRUE # converged TRUE # optim.message CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH data(gwas1.example, package='HDL') HDL::HDL.h2(gwas1.example, LD.path.new)  # 246015 out of 246015 (100%) SNPs in reference panel are available in the GWAS. # Estimation is ongoing ... 100%  # Integrating piecewise results  # Point estimate: # Heritability:  0.1407  # Continuing computing standard error with jackknife # Progress... 100%  # Heritability:  0.1407 (0.0073) # P:  8.09e-82  # $h2 # [1] 0.1407243  # $h2.se # [1] 0.007344952  # $P # [1] 8.093035e-82  # $eigen.use # [1] 0.9"},{"path":"https://now2014.github.io/sHDL/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ao Lan. Author, maintainer. Xia Shen. Author.","code":""},{"path":"https://now2014.github.io/sHDL/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lan . Shen X. Modeling genetic architecture complex traits via stratified high-definition likelihood. (2024).","code":"@Article{,   title = {Modeling the genetic architecture of complex traits via stratified high-definition likelihood},   author = {Ao Lan and Xia Shen},   journal = {.},   year = {2024},   volume = {0},   number = {0},   pages = {0-0}, }"},{"path":[]},{"path":"https://now2014.github.io/sHDL/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"practice, density GWAS SNPs often poses challenge ensuring positive definiteness covariance matrix Σ GWAS Z-score vector z. presents significant obstacle conducting statistical modeling, positive definite Σ essential. Moreover, high density SNPs results high-dimensional problem. stratified high-definition likelihood (sHDL) extends full-likelihood framework high-definition likelihood (HDL) method (Ning et al. 2020), addressing issue transforming Σ reduced, positive definite covariance matrix Σr. Paired Cholesky decomposition, sHDL method proves highly efficient heritability enrichment analysis.","code":""},{"path":"https://now2014.github.io/sHDL/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"Install dependent R packages: install latest version sHDL package via Github, run following commands R:","code":"install.packages(c(\"RhpcBLASctl\", \"dplyr\", \"parallel\", \"remotes\")) remotes::install_github(\"now2024/sHDL\")"},{"path":"https://now2014.github.io/sHDL/index.html","id":"quick-vignette","dir":"","previous_headings":"","what":"Quick vignette","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"Download LD reference panel HDL software: Run sHDL detail please visit https://now2014.github.io/sHDL/.","code":"wget -c -t 1 \\   https://www.dropbox.com/s/fuvpwsf6r8tjd6c/UKB_array_SVD_eigen90_extraction.tar.gz?dl=0 \\   --no-check-certificate -O /path/to/UKB_array_SVD_eigen90_extraction.tar.gz  # checking the md5 = ff3fadd7ea08bd29759b6c652618cd1f md5sum /your/path/to/UKB_array_SVD_eigen90_extraction.tar.gz  # extraction tar -xvf /your/path/to/UKB_array_SVD_eigen90_extraction.tar.gz remotes::install_github(\"zhenin/HDL/HDL\") data(gwas1.example, package=\"HDL\")  library(sHDL)  ## The GWAS summary statistics for birth weight loaded from HDL package. M <- nrow(gwas1.example) set.seed(1234) D <- rbinom(M, 1, 0.01) # random D vector names(D) <- gwas1.example$SNP  ## The path to the directory where linkage disequilibrium (LD) information is stored. LD.path <- \"/your/path/to/UKB_array_SVD_eigen90_extraction\"  ## To speed up the test, we set a large lam.cut value. res.sHDL <- sHDL(D, gwas1.example, LD.path, nthreads=4, stepwise=TRUE, lam.cut=10, Dr.path=NULL, mode=\"memory\") print(as.data.frame(res.sHDL))"},{"path":"https://now2014.github.io/sHDL/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"use sHDL software, please cite: Lan . Shen X. Modeling genetic architecture complex traits via stratified high-definition likelihood. (2024). Ning, Z., Pawitan, Y. & Shen, X. High-definition likelihood inference genetic correlations across human complex traits. Nat Genet (2020).","code":""},{"path":"https://now2014.github.io/sHDL/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"Reporting bugs opening new issue Github page. Sending email authors: Ao Lan Xia Shen.","code":""},{"path":"https://now2014.github.io/sHDL/index.html","id":"future-plan","dir":"","previous_headings":"","what":"Future plan","title":"Stratified high-definition likelihood inference of heritability\n        enrichment","text":"repository integrated HDL software future.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"Perform heritability enrichment analysis trait based GWAS summary statistics.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"","code":"sHDL(   D,   gwas.df,   LD.path,   output.file = NULL,   nthreads = 1,   stepwise = TRUE,   fill.missing.N = NULL,   lim = exp(-18),   lam.cut = NULL,   Dr.path = \"./Dr\",   overwrite = FALSE,   verbose = FALSE,   fix.h2 = NULL,   fix.intercept = NULL,   maxit = 1000,   pgtol = 0.001,   start.v = c(1, 0.1, 1),   mode = c(\"disk\", \"memory\"),   pattern = \".*chr(\\\\d{1,2})\\\\.(\\\\d{1,2})[_\\\\.].*\",   norm.method = c(\"minmax\", \"scaled\", \"none\") )"},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"D vector genomic annotations vector names SNP IDs. gwas.df data frame including GWAS summary statistics genetic variants trait. input data frame include following columns: SNP, SNP ID; A1, effect allele; A2, reference allele; N, sample size; Z, z-score; Z given, alternatively, may provide: b, estimate marginal effect GWAS; se, standard error estimates marginal effects GWAS. LD.path Path directory linkage disequilibrium (LD) information stored, compatible HDL LD reference panels. output.file log results written. specify file, log printed console. nthreads Number threads use, default nthreads = 1. stepwise Whether estimate enrichment fold estimating heritability intercept first, default stepwise = FALSE. fix.h2 fix.intercept NULL, stepwise overridden. fill.missing.N sample size missing GWAS summary statistics, fill.missing.N used fill missing values. lim Tolerance limitation ensure positive-definiteness covariance matrices, default lim = exp(-18). lam.cut Eigenvalue cutoff LD matrices, default lam.cut = NULL, means cutoff. Dr.path Path directory Dr matrices stored, default Dr.path = \"./Dr\". overwrite Whether overwrite existing Dr matrices, default overwrite = FALSE. verbose Whether print log console, default verbose = FALSE. fix.h2 Whether fix heritability fix.h2 estimate heritability, default fix.h2 = NULL, means estimate heritability. fix.intercept Whether fix intercept fix.intercept estimate intercept, default fix.intercept = NULL, means estimate intercept. maxit Maximum number iterations, default maxit = 1000. pgtol Tolerance convergence, default pgtol = 1e-3. start.v vector starting values c(fold, h2, intercept) optimization. mode Whether store Dr disk memory, default mode = \"disk\". mode = \"disk\", Dr stored disk (path returned ) lam returned. mode = \"memory\", Dr lam returned. pattern Chromosome picece pattern LD files, default \".*chr(\\d{1,2})\\.(\\d{1,2})[_\\.].*\". norm.method normalization method, either \"minmax\" (default), \"scaled\" \"none\". \"minmax\", annotation weight vector D normalized [0, 1]. \"scaled\", sum normalized vector D scaled number annotated SNPs. \"none\", annotation weight vector D normalized.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"list returned : time time used optimization. fold estimated heritability enrichment fold. h2 estimated SNP-based heritability. intercept estimated intercept. fold.se standard error estimated heritability enrichment fold. h2.se standard error estimated heritability. intercept.se standard error estimated intercept. fold.p P-value based Wald test estimated heritability enrichment fold. h2.p P-value based Wald test estimated heritability. intercept.p P-value based Wald test estimated intercept. stepwise Whether optimization done stepwise manner. converged Whether optimization converges. message message returned optim.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"Users can download precomputed eigenvalues eigenvectors LD correlation matrices European ancestry population. download link can found https://github.com/zhenin/HDL/wiki/Reference-panels LD matrices eigen-decomposition 335,265 genomic British UK Biobank individuals. Three sets reference panel provided: 1) 1,029,876 QCed UK Biobank imputed HapMap3 SNPs. size 33 GB unzipping. Although takes time, using imputed panel provides accurate estimates genetic correlations. Therefore GWAS includes HapMap3 SNPs, recommend using imputed reference panel. 2) 769,306 QCed UK Biobank imputed HapMap2 SNPs. size 18 GB unzipping.one GWAS includes HapMap 2 SNPs, many SNPs (1 HapMap2 panel proper used HDL. 3) 307,519 QCed UK Biobank Axiom Array SNPs. size 7.5 GB unzipping.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"Lan Shen X (2024). Modeling Genetic Architecture Complex Traits via Stratified High-Definition Likelihood.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"Ao Lan, Xia Shen","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform heritability enrichment analysis of trait based on GWAS summary statistics. — sHDL","text":"","code":"if (FALSE) { ## The GWAS summary statistics for birth weight loaded from HDL package. data(gwas1.example, package='HDL') M <- nrow(gwas1.example) set.seed(1234) D <- rbinom(M, 1, 0.01) # random D vector names(D) <- gwas1.example$SNP  ## The path to the directory where linkage disequilibrium (LD) information is stored. LD.path <- \"path/to/UKB_array_SVD_eigen90_extraction\"  ## To speed up the test, we set a large lam.cut value. res.sHDL <- sHDL(D, gwas1.example, LD.path, nthreads=4, stepwise=TRUE, lam.cut=10, Dr.path=NULL, mode=\"memory\") print(as.data.frame(res.sHDL)) }"},{"path":"https://now2014.github.io/sHDL/reference/sHDL.optim.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximize the log likelihood to infer the heritability enrichment fold. — sHDL.optim","title":"Maximize the log likelihood to infer the heritability enrichment fold. — sHDL.optim","text":"Maximize log likelihood infer heritability enrichment fold.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.optim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximize the log likelihood to infer the heritability enrichment fold. — sHDL.optim","text":"","code":"sHDL.optim(   ref.data,   N,   start.v = c(1, 0.1, 1),   output.file = NULL,   log.file = \"\",   stepwise = FALSE,   fix.h2 = NULL,   fix.intercept = NULL,   lim = exp(-18),   verbose = FALSE,   clust = NULL,   lwr = NULL,   upr = NULL,   maxit = 1000,   pgtol = 0.001 )"},{"path":"https://now2014.github.io/sHDL/reference/sHDL.optim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximize the log likelihood to infer the heritability enrichment fold. — sHDL.optim","text":"ref.data list data matched LD reference generated sHDL.reduct.dim. N sample size GWAS. start.v vector starting values c(fold, h2, intercept) optimization. output.file log results written. log.file log written. stepwise Whether estimate enrichment fold estimating heritability intercept first, default stepwise = FALSE. fix.h2 fix.intercept NULL, stepwise overridden. fix.h2 Whether fix heritability fix.h2 estimate heritability, default fix.h2 = NULL, means estimate heritability. fix.intercept Whether fix intercept fix.intercept estimate intercept, default fix.intercept = NULL, means estimate intercept. lim Tolerance limitation ensure positive-definiteness covariance matrices, default lim = exp(-18). verbose Whether print log console, default verbose = FALSE. clust cluster object generated parallel::makeCluster. lwr Lower bounds parameters. upr Upper bounds parameters. maxit Maximum number iterations, default maxit = 1000. pgtol Tolerance convergence, default pgtol = 1e-3.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.optim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximize the log likelihood to infer the heritability enrichment fold. — sHDL.optim","text":"list returned : time Time elapsed seconds optimization. fold estimated heritability enrichment fold. h2 estimated SNP-based heritability. intercept estimated intercept. fold.se standard error estimated heritability enrichment fold. h2.se standard error estimated heritability. intercept.se standard error estimated intercept. fold.p P-value based Wald test estimated heritability enrichment fold. h2.p P-value based Wald test estimated heritability. intercept.p P-value based Wald test estimated intercept. stepwise Whether optimization done stepwise manner. converged Whether optimization converges. message message returned optim.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.rebuild.ref.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-build the LD reference panel with given SNPs. — sHDL.rebuild.ref","title":"Re-build the LD reference panel with given SNPs. — sHDL.rebuild.ref","text":"Re-build LD reference panel given SNPs.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.rebuild.ref.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-build the LD reference panel with given SNPs. — sHDL.rebuild.ref","text":"","code":"sHDL.rebuild.ref(   LD.path,   gwas.snps,   LD.path.new,   nthreads = 1,   lam.cut = NULL,   pattern = \".*chr(\\\\d{1,2})\\\\.(\\\\d{1,2})[_\\\\.].*\" )"},{"path":"https://now2014.github.io/sHDL/reference/sHDL.rebuild.ref.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-build the LD reference panel with given SNPs. — sHDL.rebuild.ref","text":"LD.path Path .rda file Eigen decomposition LD matrix stored. gwas.snps vector contains SNP IDs GWAS summary statistics. LD.path.new new path re-built LD reference. nthreads Number threads use, default nthreads = 1. lam.cut Eigenvalue cutoff LD matrices, default lam.cut = NULL, means cutoff original LD reference panel. pattern Chromosome picece pattern LD files, default \".*chr(\\d{1,2})\\.(\\d{1,2})[_\\.].*\".","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.rebuild.ref.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-build the LD reference panel with given SNPs. — sHDL.rebuild.ref","text":"new path re-built LD reference.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.reduct.dim.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce the dimension of covariance matrix by converting z (D) to zr (Dr). — sHDL.reduct.dim","title":"Reduce the dimension of covariance matrix by converting z (D) to zr (Dr). — sHDL.reduct.dim","text":"Reduce dimension covariance matrix converting z (D) zr (Dr).","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.reduct.dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce the dimension of covariance matrix by converting z (D) to zr (Dr). — sHDL.reduct.dim","text":"","code":"sHDL.reduct.dim(   LD.path,   z = NULL,   D = NULL,   lam.cut = NULL,   Dr.path = NULL,   overwrite = FALSE,   mode = c(\"disk\", \"memory\"),   nthreads = 1,   pattern = \".*chr(\\\\d{1,2})\\\\.(\\\\d{1,2})[_\\\\.].*\",   norm.method = c(\"minmax\", \"scaled\", \"none\") )"},{"path":"https://now2014.github.io/sHDL/reference/sHDL.reduct.dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce the dimension of covariance matrix by converting z (D) to zr (Dr). — sHDL.reduct.dim","text":"LD.path Path .rda file Eigen decomposition LD matrix stored. z matrix Z-scores rownames SNP IDs. Supporting multiple columns multiple traits. D vector genomic annotations vector names SNP IDs. lam.cut Eigenvalue cutoff LD matrices, default lam.cut = NULL, means cutoff. Dr.path Path directory Dr matrices stored, default Dr.path = NULL, means store Dr disk. overwrite Whether overwrite existing Dr matrices, default overwrite = FALSE. mode Whether store Dr disk memory, default mode = \"disk\". mode = \"disk\", Dr stored disk (path returned ) lam returned. mode = \"memory\", Dr lam returned. nthreads Number threads use matrix operations, default nthreads = 1. pattern Chromosome picece pattern LD files, default \".*chr(\\d{1,2})\\.(\\d{1,2})[_\\.].*\". norm.method normalization method, either \"minmax\" (default), \"scaled\" \"none\". \"minmax\", annotation weight vector D normalized [0, 1]. \"scaled\", sum normalized vector D scaled number annotated SNPs. \"none\", annotation weight vector D normalized.","code":""},{"path":"https://now2014.github.io/sHDL/reference/sHDL.reduct.dim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce the dimension of covariance matrix by converting z (D) to zr (Dr). — sHDL.reduct.dim","text":"list returned : Dr reduct RDR matrix. zr reduct z-score vector. lam eigenvalues LD matrix. Md sum annotation weights SNPs given LD matrix. M number SNPs given LD matrix.","code":""}]
